{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":33884,"sourceType":"datasetVersion","datasetId":1864}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-12T18:23:23.942625Z","iopub.execute_input":"2025-12-12T18:23:23.942937Z","iopub.status.idle":"2025-12-12T18:23:25.678014Z","shell.execute_reply.started":"2025-12-12T18:23:23.942911Z","shell.execute_reply":"2025-12-12T18:23:25.677244Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!pip install \"protobuf==3.20.3\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T18:23:35.255486Z","iopub.execute_input":"2025-12-12T18:23:35.255758Z","iopub.status.idle":"2025-12-12T18:23:38.367860Z","shell.execute_reply.started":"2025-12-12T18:23:35.255734Z","shell.execute_reply":"2025-12-12T18:23:38.367124Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.11/dist-packages (3.20.3)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport shutil\n\nbase_path = \"/kaggle/input/food41\"  # your dataset\nimages_path = f\"{base_path}/images\"\nmeta_path = f\"{base_path}/meta/meta\"\n\noutput_root = \"/kaggle/working/food101_split\"\ntrain_dir = f\"{output_root}/train\"\ntest_dir = f\"{output_root}/test\"\n\n# Create output folders\nos.makedirs(train_dir, exist_ok=True)\nos.makedirs(test_dir, exist_ok=True)\n\n# Read split files\nwith open(f\"{meta_path}/train.txt\") as f:\n    train_files = [line.strip() for line in f]\n\nwith open(f\"{meta_path}/test.txt\") as f:\n    test_files = [line.strip() for line in f]\n\n# Move images into train/test folder structure\nfor fpath in train_files:\n    cls = fpath.split(\"/\")[0]\n    os.makedirs(f\"{train_dir}/{cls}\", exist_ok=True)\n    shutil.copy(f\"{images_path}/{fpath}.jpg\", f\"{train_dir}/{cls}/\")\n\nfor fpath in test_files:\n    cls = fpath.split(\"/\")[0]\n    os.makedirs(f\"{test_dir}/{cls}\", exist_ok=True)\n    shutil.copy(f\"{images_path}/{fpath}.jpg\", f\"{test_dir}/{cls}/\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T18:23:40.170533Z","iopub.execute_input":"2025-12-12T18:23:40.171629Z","iopub.status.idle":"2025-12-12T18:37:11.943556Z","shell.execute_reply.started":"2025-12-12T18:23:40.171585Z","shell.execute_reply":"2025-12-12T18:37:11.942820Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import tensorflow as tf\n\n# Load the training data\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n    \"/kaggle/working/food101_split/train\",\n    image_size=(224, 224),\n    batch_size=32,         \n    label_mode='categorical' \n)\n\n# Load the test data\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n    \"/kaggle/working/food101_split/test\",\n    image_size=(224, 224),\n    batch_size=32,\n    label_mode='categorical' \n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T19:10:47.748790Z","iopub.execute_input":"2025-12-12T19:10:47.749622Z","iopub.status.idle":"2025-12-12T19:10:51.886899Z","shell.execute_reply.started":"2025-12-12T19:10:47.749595Z","shell.execute_reply":"2025-12-12T19:10:51.886214Z"}},"outputs":[{"name":"stdout","text":"Found 75750 files belonging to 101 classes.\nFound 25250 files belonging to 101 classes.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\n\nmodel = models.Sequential([\n    layers.Input(shape=(224, 224, 3)),\n\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.1), \n    layers.RandomZoom(0.1),     \n    layers.Rescaling(1./255),\n    \n    layers.Conv2D(32, (3, 3), padding='same'), \n    layers.BatchNormalization(),     \n    layers.Activation('relu'),                 \n    layers.MaxPooling2D((2, 2)),\n    \n    layers.Conv2D(64, (3, 3), padding='same'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(128, (3, 3), padding='same'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(256, (3, 3), padding='same'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.MaxPooling2D((2, 2)),\n    \n    layers.Dropout(0.5), \n    layers.GlobalAveragePooling2D(),\n    layers.Dense(256, activation='relu'),\n    layers.Dense(101, activation='softmax')\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T19:10:53.189863Z","iopub.execute_input":"2025-12-12T19:10:53.190521Z","iopub.status.idle":"2025-12-12T19:10:53.295132Z","shell.execute_reply.started":"2025-12-12T19:10:53.190494Z","shell.execute_reply":"2025-12-12T19:10:53.294231Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Train\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\nhistory = model.fit(\n    train_ds, \n    validation_data=test_ds, \n    epochs=10  # Start with 10 to see how it goes\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T19:10:55.955090Z","iopub.execute_input":"2025-12-12T19:10:55.955846Z","iopub.status.idle":"2025-12-12T19:47:23.949526Z","shell.execute_reply.started":"2025-12-12T19:10:55.955821Z","shell.execute_reply":"2025-12-12T19:47:23.948706Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"E0000 00:00:1765566661.291890     724 meta_optimizer.cc:966] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/sequential_2_1/dropout_2_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 93ms/step - accuracy: 0.0554 - loss: 4.2983 - val_accuracy: 0.0531 - val_loss: 4.5682\nEpoch 2/10\n\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 91ms/step - accuracy: 0.1367 - loss: 3.6879 - val_accuracy: 0.1104 - val_loss: 3.9761\nEpoch 3/10\n\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 92ms/step - accuracy: 0.1950 - loss: 3.3650 - val_accuracy: 0.1029 - val_loss: 4.2592\nEpoch 4/10\n\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 92ms/step - accuracy: 0.2429 - loss: 3.1251 - val_accuracy: 0.1202 - val_loss: 4.1852\nEpoch 5/10\n\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 93ms/step - accuracy: 0.2796 - loss: 2.9304 - val_accuracy: 0.2181 - val_loss: 3.2959\nEpoch 6/10\n\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m220s\u001b[0m 93ms/step - accuracy: 0.3152 - loss: 2.7730 - val_accuracy: 0.2627 - val_loss: 3.0670\nEpoch 7/10\n\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 92ms/step - accuracy: 0.3405 - loss: 2.6578 - val_accuracy: 0.1799 - val_loss: 3.7613\nEpoch 8/10\n\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m217s\u001b[0m 92ms/step - accuracy: 0.3635 - loss: 2.5535 - val_accuracy: 0.2381 - val_loss: 3.3266\n\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 92ms/step - accuracy: 0.3815 - loss: 2.4673 - val_accuracy: 0.2751 - val_loss: 3.0603\nEpoch 10/10\n\u001b[1m2368/2368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m218s\u001b[0m 92ms/step - accuracy: 0.3968 - loss: 2.3956 - val_accuracy: 0.3137 - val_loss: 2.8261\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Save the entire model (architecture + weights)\nmodel.save(\"food101_custom_cnn_31acc.keras\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-12T19:48:16.681560Z","iopub.execute_input":"2025-12-12T19:48:16.682264Z","iopub.status.idle":"2025-12-12T19:48:17.243957Z","shell.execute_reply.started":"2025-12-12T19:48:16.682232Z","shell.execute_reply":"2025-12-12T19:48:17.243175Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"from tensorflow.keras import layers, models\n\n\nmodel2 = models.Sequential([\n    layers.Input(shape=(224, 224, 3)),\n\n    layers.RandomFlip(\"horizontal\"),\n    layers.RandomRotation(0.1), \n    layers.RandomZoom(0.1),     \n    layers.Rescaling(1./255),\n    \n    layers.Conv2D(32, (3, 3), padding='same'), \n    layers.BatchNormalization(),     \n    layers.Activation('relu'),                 \n    layers.MaxPooling2D((2, 2)),\n    \n    layers.Conv2D(64, (3, 3), padding='same'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(128, (3, 3), padding='same'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.MaxPooling2D((2, 2)),\n\n    layers.Conv2D(256, (3, 3), padding='same'),\n    layers.BatchNormalization(),\n    layers.Activation('relu'),\n    layers.MaxPooling2D((2, 2)),\n    \n    layers.Dropout(0.5), \n    layers.GlobalAveragePooling2D(),\n    layers.Dense(256, activation='relu'),\n    layers.Dense(101, activation='softmax')\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the scheduler\nlr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.2,    # Cut learning rate by 5x (e.g. 0.001 -> 0.0002)\n    patience=2,    # Wait 2 epochs. If no improvement, cut the rate.\n    min_lr=1e-6,\n    verbose=1      # Print a message when it happens\n)\n\n# Train with the scheduler\nhistory = model2.fit(\n    train_ds, \n    validation_data=test_ds, \n    epochs=15,             # Increase to 15 or 20, the scheduler handles the timing\n    callbacks=[lr_scheduler] \n)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}